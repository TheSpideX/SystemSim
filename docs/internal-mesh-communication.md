# Internal Mesh Communication Protocols

## ğŸ”— **Service Mesh Communication Architecture**

### **Overview**
The internal service mesh uses **three types of communication** between all services:

1. **gRPC (Synchronous Internal Mesh)**: For immediate response operations requiring strong consistency between services
2. **HTTP/2 (Client Communication)**: For client-facing operations and development/debugging
3. **Redis Pub/Sub + Streams (Asynchronous & Real-time)**: For fire-and-forget operations, real-time data streaming, and heavy processing

All services are **equal mesh participants**, including the API Gateway, with each service maintaining all three communication channels.

### **Mesh Participants**
```
Full Mesh Network (Three-Layer Communication):

API Gateway (Port 8000):
â”œâ”€â”€ HTTP/2 Server: Client interface (web apps, mobile apps)
â”œâ”€â”€ gRPC Client Pool: Internal mesh communication
â””â”€â”€ Redis Pub/Sub: System events and real-time data

Auth Service:
â”œâ”€â”€ HTTP/2 Server (Port 9001): Client auth operations (register, login, profile)
â”œâ”€â”€ gRPC Server (Port 9000): Internal mesh (token validation, permissions)
â””â”€â”€ Redis Pub/Sub: Login events, background email processing

Project Service:
â”œâ”€â”€ HTTP/2 Server (Port 10001): Client project operations (CRUD, management)
â”œâ”€â”€ gRPC Server (Port 10000): Internal mesh (project access, validation)
â””â”€â”€ Redis Pub/Sub: Project events, collaboration notifications

Simulation Service:
â”œâ”€â”€ HTTP/2 Server (Port 11001): Client simulation operations (run, configure)
â”œâ”€â”€ gRPC Server (Port 11000): Internal mesh (status, execution control)
â””â”€â”€ Redis Streams: Real-time simulation data streaming, results broadcasting

Each service maintains ALL THREE communication channels simultaneously
```

## ğŸ—ï¸ **Three-Layer Communication Architecture**

### **Layer 1: gRPC Internal Mesh (Synchronous)**
- **Purpose**: High-performance service-to-service communication
- **Protocol**: gRPC over HTTP/2 with Protocol Buffers
- **Port Pattern**: X000 (Auth: 9000, Project: 10000, Simulation: 11000)
- **Use Cases**:
  - Token validation between services
  - Permission checking for authorization
  - User context retrieval
  - Service health checks
  - Real-time queries requiring immediate response
- **Connection Management**: Dynamic connection pools (5-20 connections per service pair)
- **Performance**: 2-10x faster than HTTP/JSON for internal calls

### **Layer 2: HTTP/2 Client Interface (Client Communication)**
- **Purpose**: Client-facing operations and development/debugging
- **Protocol**: HTTP/2 + JSON
- **Port Pattern**: X001 (Auth: 9001, Project: 10001, Simulation: 11001)
- **Use Cases**:
  - User registration and authentication
  - Profile and account management
  - Project CRUD operations
  - Simulation configuration and control
  - Admin operations and management
- **Features**: CORS, rate limiting, security headers, request validation
- **Development**: Always enabled for debugging; can be disabled in production

### **Layer 3: Redis Pub/Sub + Streams (Asynchronous & Real-time)**
- **Purpose**: Event publishing, background tasks, and real-time data streaming
- **Protocol**: Redis Pub/Sub for events, Redis Streams for real-time data
- **Use Cases**:
  - **Events**: Login/logout, permission changes, system announcements
  - **Background Tasks**: Email sending, data processing, cleanup jobs
  - **Real-time Streaming**: Live simulation data, progress updates, metrics
  - **Notifications**: User notifications, system alerts, collaboration updates
- **Patterns**: Publisher/Subscriber for events, Producer/Consumer for streams
- **Scalability**: Horizontal scaling with Redis Cluster

## ğŸ¯ **gRPC Service Contracts (Layer 1: Internal Mesh)**

### **API Gateway gRPC Interface (Port 8000)**

#### **Service Definition**
```protobuf
syntax = "proto3";

package gateway;

service GatewayService {
  // Client session management
  rpc RegisterClient(RegisterClientRequest) returns (RegisterClientResponse);
  rpc UnregisterClient(UnregisterClientRequest) returns (UnregisterClientResponse);

  // WebSocket message routing
  rpc RouteMessage(RouteMessageRequest) returns (RouteMessageResponse);
  rpc BroadcastMessage(BroadcastMessageRequest) returns (BroadcastMessageResponse);

  // Client connection info
  rpc GetConnectedClients(GetConnectedClientsRequest) returns (GetConnectedClientsResponse);
  rpc GetClientInfo(GetClientInfoRequest) returns (GetClientInfoResponse);

  // Health check
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}
```

#### **Message Definitions**
```protobuf
message RegisterClientRequest {
  string client_id = 1;
  string user_id = 2;
  repeated string subscriptions = 3;
  string connection_type = 4; // "websocket" or "http"
}

message RegisterClientResponse {
  bool success = 1;
  string session_id = 2;
  string message = 3;
}

message RouteMessageRequest {
  string target_user_id = 1;
  string message_type = 2;
  bytes payload = 3;
  string source_service = 4;
}

message RouteMessageResponse {
  bool delivered = 1;
  int32 client_count = 2;
  string message = 3;
}
```

### **Auth Service gRPC Interface (Port 9000)**

#### **Service Definition**
```protobuf
syntax = "proto3";

package auth;

service AuthService {
  // Token validation for other services
  rpc ValidateToken(ValidateTokenRequest) returns (ValidateTokenResponse);
  
  // Get user context with permissions
  rpc GetUserContext(GetUserContextRequest) returns (GetUserContextResponse);
  
  // Check specific permissions
  rpc CheckPermission(CheckPermissionRequest) returns (CheckPermissionResponse);
  
  // Validate user session
  rpc ValidateSession(ValidateSessionRequest) returns (ValidateSessionResponse);
  
  // Get user roles and permissions
  rpc GetUserPermissions(GetUserPermissionsRequest) returns (GetUserPermissionsResponse);
  
  // Health check
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}
```

#### **Message Definitions**
```protobuf
message ValidateTokenRequest {
  string token = 1;
  string calling_service = 2;
  string request_id = 3;
}

message ValidateTokenResponse {
  bool valid = 1;
  string user_id = 2;
  string email = 3;
  bool is_admin = 4;
  string session_id = 5;
  repeated string permissions = 6;
  int64 expires_at = 7;
}

message GetUserContextRequest {
  string user_id = 1;
  string calling_service = 2;
}

message GetUserContextResponse {
  string user_id = 1;
  string email = 2;
  string name = 3;
  repeated string roles = 4;
  repeated string permissions = 5;
  bool is_active = 6;
  int64 last_login = 7;
}

message CheckPermissionRequest {
  string user_id = 1;
  string permission = 2;
  string resource_id = 3;
  string calling_service = 4;
}

message CheckPermissionResponse {
  bool allowed = 1;
  string reason = 2;
}
```

### **Project Service gRPC Interface (Port 10000)**

#### **Service Definition**
```protobuf
syntax = "proto3";

package project;

service ProjectService {
  // Project CRUD operations
  rpc CreateProject(CreateProjectRequest) returns (CreateProjectResponse);
  rpc GetProject(GetProjectRequest) returns (GetProjectResponse);
  rpc UpdateProject(UpdateProjectRequest) returns (UpdateProjectResponse);
  rpc DeleteProject(DeleteProjectRequest) returns (DeleteProjectResponse);
  rpc ListProjects(ListProjectsRequest) returns (ListProjectsResponse);
  
  // Project sharing and permissions
  rpc ShareProject(ShareProjectRequest) returns (ShareProjectResponse);
  rpc GetProjectPermissions(GetProjectPermissionsRequest) returns (GetProjectPermissionsResponse);
  
  // Template management
  rpc GetTemplate(GetTemplateRequest) returns (GetTemplateResponse);
  rpc ListTemplates(ListTemplatesRequest) returns (ListTemplatesResponse);
  
  // Collaboration features
  rpc JoinCollaboration(JoinCollaborationRequest) returns (JoinCollaborationResponse);
  rpc LeaveCollaboration(LeaveCollaborationRequest) returns (LeaveCollaborationResponse);
  
  // Health check
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}
```

#### **Message Definitions**
```protobuf
message CreateProjectRequest {
  string user_id = 1;
  string name = 2;
  string description = 3;
  string template_id = 4;
  map<string, string> configuration = 5;
  bool is_public = 6;
}

message CreateProjectResponse {
  string project_id = 1;
  string name = 2;
  string status = 3;
  int64 created_at = 4;
  string template_used = 5;
}

message GetProjectRequest {
  string project_id = 1;
  string user_id = 2;
  bool include_configuration = 3;
}

message GetProjectResponse {
  string project_id = 1;
  string name = 2;
  string description = 3;
  string owner_id = 4;
  map<string, string> configuration = 5;
  repeated string collaborators = 6;
  int64 created_at = 7;
  int64 updated_at = 8;
  string status = 9;
}
```

### **Simulation Service gRPC Interface (Port 11000)**

#### **Service Definition**
```protobuf
syntax = "proto3";

package simulation;

service SimulationService {
  // Simulation lifecycle
  rpc StartSimulation(StartSimulationRequest) returns (StartSimulationResponse);
  rpc StopSimulation(StopSimulationRequest) returns (StopSimulationResponse);
  rpc GetSimulationStatus(GetSimulationStatusRequest) returns (GetSimulationStatusResponse);
  rpc GetSimulationResults(GetSimulationResultsRequest) returns (GetSimulationResultsResponse);
  
  // Real-time simulation data
  rpc GetLiveMetrics(GetLiveMetricsRequest) returns (GetLiveMetricsResponse);
  rpc GetPerformanceAnalysis(GetPerformanceAnalysisRequest) returns (GetPerformanceAnalysisResponse);
  
  // Simulation configuration
  rpc ValidateConfiguration(ValidateConfigurationRequest) returns (ValidateConfigurationResponse);
  rpc GetSimulationHistory(GetSimulationHistoryRequest) returns (GetSimulationHistoryResponse);
  
  // Health check
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}
```

#### **Message Definitions**
```protobuf
message StartSimulationRequest {
  string user_id = 1;
  string project_id = 2;
  map<string, string> configuration = 3;
  repeated string components = 4;
  int32 duration_seconds = 5;
  bool enable_real_time = 6;
}

message StartSimulationResponse {
  string simulation_id = 1;
  string status = 2;
  int64 started_at = 3;
  string websocket_channel = 4;
  int32 estimated_duration = 5;
}

message GetSimulationStatusRequest {
  string simulation_id = 1;
  string user_id = 2;
}

message GetSimulationStatusResponse {
  string simulation_id = 1;
  string status = 2;
  int32 progress_percentage = 3;
  int64 started_at = 4;
  int64 estimated_completion = 5;
  repeated string active_components = 6;
  map<string, double> current_metrics = 7;
}
```

## ğŸ”„ **Redis Pub/Sub + Streams Communication (Layer 3: Asynchronous & Real-time)**

### **Dual Redis Architecture**
```
Redis Cluster Configuration:

1. Redis Pub/Sub (Events & Notifications):
   - Purpose: Event broadcasting, notifications, background tasks
   - Pattern: Publisher/Subscriber
   - Persistence: Non-persistent (fire-and-forget)
   - Use Cases: Login events, system announcements, background jobs

2. Redis Streams (Real-time Data Streaming):
   - Purpose: High-throughput real-time data streaming
   - Pattern: Producer/Consumer with consumer groups
   - Persistence: Persistent with configurable retention
   - Use Cases: Live simulation data, metrics streaming, real-time collaboration
```

### **Channel Organization**

#### **Event Channels (Redis Pub/Sub - Low-Medium Frequency)**
```
Event Broadcasting Channels:
â”œâ”€â”€ auth:events:login â†’ User login events (100-1K/hour)
â”œâ”€â”€ auth:events:logout â†’ User logout events (100-1K/hour)
â”œâ”€â”€ auth:events:permission_changed â†’ Permission updates (10-100/hour)
â”œâ”€â”€ project:events:created â†’ Project creation events (10-100/hour)
â”œâ”€â”€ project:events:shared â†’ Project sharing events (10-100/hour)
â”œâ”€â”€ project:events:updated â†’ Project modification events (100-1K/hour)
â”œâ”€â”€ simulation:events:started â†’ Simulation start events (10-100/hour)
â”œâ”€â”€ simulation:events:completed â†’ Simulation completion events (10-100/hour)
â””â”€â”€ system:announcements â†’ System-wide messages (1-10/hour)
```

#### **Real-time Streaming Channels (Redis Streams - High Frequency)**
```
High-Throughput Data Streams:
â”œâ”€â”€ simulation:stream:{simulation_id} â†’ Live simulation metrics (1K-100K/sec)
â”œâ”€â”€ collaboration:stream:{project_id} â†’ Real-time editing updates (100-10K/sec)
â”œâ”€â”€ monitoring:stream:metrics â†’ System performance data (1K-10K/sec)
â”œâ”€â”€ analytics:stream:events â†’ User interaction tracking (100-10K/sec)
â”œâ”€â”€ notifications:stream:{user_id} â†’ User-specific real-time notifications (10-1K/sec)
â””â”€â”€ system:stream:health â†’ Service health monitoring (100-1K/sec)
```

#### **Background Processing Channels (Redis Pub/Sub - Medium Frequency)**
```
Async Work Queues:
â”œâ”€â”€ async:email:queue â†’ Background email sending (100-1K/hour)
â”œâ”€â”€ async:reports:queue â†’ Report generation (10-100/hour)
â”œâ”€â”€ async:exports:queue â†’ Data export processing (10-100/hour)
â”œâ”€â”€ async:cleanup:queue â†’ Background cleanup tasks (10-100/hour)
â”œâ”€â”€ async:analytics:queue â†’ Analytics processing (100-1K/hour)
â””â”€â”€ async:notifications:queue â†’ Notification delivery (100-10K/hour)
```

### **Service Subscription Patterns**

#### **API Gateway Subscriptions**
```go
// API Gateway subscribes to ALL channels for WebSocket broadcasting
func (ag *APIGateway) initializeRedisSubscriptions() {
    ag.pubsub = ag.redis.PSubscribe(
        "auth:events:*",           // All auth events
        "project:events:*",        // All project events
        "simulation:events:*",     // All simulation events
        "simulation:data:*",       // Real-time simulation data
        "notifications:user:*",    // All user notifications
        "system:*",                // System-wide messages
    )

    // Handle messages and route to WebSocket clients
    go ag.handleRedisMessages()
}
```

#### **Auth Service Subscriptions**
```go
func (auth *AuthService) initializeRedisSubscriptions() {
    auth.pubsub = auth.redis.Subscribe(
        "async:email:queue",       // Process email sending
        "system:announcements",    // System messages
    )

    // Publish auth events
    auth.publisher = auth.redis
}

// Publishing auth events
func (auth *AuthService) publishLoginEvent(userID string) {
    event := AuthEvent{
        Type:      "login",
        UserID:    userID,
        Timestamp: time.Now(),
    }
    auth.publisher.Publish("auth:events:login", event)
}
```

#### **Project Service Subscriptions**
```go
func (project *ProjectService) initializeRedisSubscriptions() {
    project.pubsub = project.redis.Subscribe(
        "auth:events:permission_changed", // User permission updates
        "async:reports:queue",             // Report generation
        "async:exports:queue",             // Data export processing
        "system:announcements",            // System messages
    )
}

// Publishing project events
func (project *ProjectService) publishProjectCreated(projectID, userID string) {
    event := ProjectEvent{
        Type:      "created",
        ProjectID: projectID,
        UserID:    userID,
        Timestamp: time.Now(),
    }
    project.publisher.Publish("project:events:created", event)
}
```

#### **Simulation Service Subscriptions**
```go
func (sim *SimulationService) initializeRedisSubscriptions() {
    sim.pubsub = sim.redis.Subscribe(
        "project:events:updated",    // Project configuration changes
        "async:cleanup:queue",       // Cleanup old simulation data
        "async:analytics:queue",     // Analytics processing
        "system:announcements",      // System messages
    )
}

// Publishing high-frequency simulation data using Redis Streams
func (sim *SimulationService) publishSimulationData(simulationID string, metrics SimulationMetrics) {
    streamKey := fmt.Sprintf("simulation:stream:%s", simulationID)

    // Use Redis Streams for high-throughput real-time data
    sim.redisClient.XAdd(ctx, &redis.XAddArgs{
        Stream: streamKey,
        Values: map[string]interface{}{
            "timestamp":     time.Now().UnixNano(),
            "cpu_usage":     metrics.CPUUsage,
            "memory_usage":  metrics.MemoryUsage,
            "network_io":    metrics.NetworkIO,
            "active_nodes":  metrics.ActiveNodes,
            "throughput":    metrics.Throughput,
            "latency":       metrics.Latency,
            "error_rate":    metrics.ErrorRate,
        },
        MaxLen: 10000, // Keep last 10K entries
    })
}
```

### **Real-time Simulation Data Streaming**

#### **Redis Streams Architecture for Simulation**
```go
// Simulation Service: High-frequency data producer
type SimulationStreamer struct {
    redisClient *redis.Client
    streamKey   string
    batchSize   int
    flushInterval time.Duration
}

// Stream real-time simulation metrics (1K-100K messages/second)
func (s *SimulationStreamer) StreamMetrics(simulationID string) {
    streamKey := fmt.Sprintf("simulation:stream:%s", simulationID)

    ticker := time.NewTicker(100 * time.Millisecond) // 10 updates/second
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            metrics := s.collectCurrentMetrics()

            // Batch multiple metrics for efficiency
            s.redisClient.XAdd(ctx, &redis.XAddArgs{
                Stream: streamKey,
                Values: map[string]interface{}{
                    "timestamp":        time.Now().UnixNano(),
                    "nodes_active":     metrics.NodesActive,
                    "nodes_failed":     metrics.NodesFailed,
                    "pods_running":     metrics.PodsRunning,
                    "services_healthy": metrics.ServicesHealthy,
                    "cpu_total":        metrics.CPUTotal,
                    "memory_total":     metrics.MemoryTotal,
                    "network_in":       metrics.NetworkIn,
                    "network_out":      metrics.NetworkOut,
                    "requests_per_sec": metrics.RequestsPerSec,
                    "avg_latency":      metrics.AvgLatency,
                    "error_rate":       metrics.ErrorRate,
                    "simulation_step":  metrics.SimulationStep,
                },
                MaxLen: 50000, // Keep last 50K entries (~1.4 hours at 10/sec)
            })
        }
    }
}
```

#### **API Gateway: Real-time Data Consumer & WebSocket Broadcaster**
```go
// API Gateway consumes simulation streams and broadcasts to WebSocket clients
type SimulationStreamConsumer struct {
    redisClient   *redis.Client
    wsManager     *WebSocketManager
    consumerGroup string
}

func (c *SimulationStreamConsumer) ConsumeSimulationStream(simulationID string) {
    streamKey := fmt.Sprintf("simulation:stream:%s", simulationID)
    consumerGroup := "api-gateway-consumers"
    consumerName := fmt.Sprintf("gateway-%s", os.Getenv("INSTANCE_ID"))

    // Create consumer group if not exists
    c.redisClient.XGroupCreate(ctx, streamKey, consumerGroup, "0")

    for {
        // Read from stream with consumer group
        streams := c.redisClient.XReadGroup(ctx, &redis.XReadGroupArgs{
            Group:    consumerGroup,
            Consumer: consumerName,
            Streams:  []string{streamKey, ">"},
            Count:    100,  // Process up to 100 messages at once
            Block:    100 * time.Millisecond,
        }).Val()

        for _, stream := range streams {
            for _, message := range stream.Messages {
                // Convert Redis stream message to WebSocket format
                wsMessage := c.formatSimulationUpdate(message.Values)

                // Broadcast to all connected clients watching this simulation
                c.wsManager.BroadcastToSimulation(simulationID, wsMessage)

                // Acknowledge message processing
                c.redisClient.XAck(ctx, streamKey, consumerGroup, message.ID)
            }
        }
    }
}
```

#### **Client WebSocket Integration**
```javascript
// Frontend receives real-time simulation data via WebSocket
const simulationSocket = new WebSocket('ws://localhost:8000/simulation/stream');

simulationSocket.onmessage = (event) => {
    const data = JSON.parse(event.data);

    if (data.type === 'simulation_metrics') {
        // Update real-time charts and dashboards
        updateCPUChart(data.cpu_total);
        updateMemoryChart(data.memory_total);
        updateNetworkChart(data.network_in, data.network_out);
        updateLatencyChart(data.avg_latency);
        updateErrorRateChart(data.error_rate);

        // Update simulation step counter
        updateSimulationProgress(data.simulation_step);
    }
};
```

#### **Performance Characteristics**
```
Real-time Simulation Streaming Performance:

Data Production (Simulation Service):
â”œâ”€â”€ Frequency: 10-100 updates/second per simulation
â”œâ”€â”€ Batch Size: 1-100 metrics per update
â”œâ”€â”€ Throughput: 1K-100K messages/second (multiple simulations)
â”œâ”€â”€ Latency: <10ms from generation to Redis
â””â”€â”€ Persistence: 50K messages (~1-5 hours of data)

Data Consumption (API Gateway):
â”œâ”€â”€ Consumer Groups: Horizontal scaling support
â”œâ”€â”€ Processing: 100 messages per batch
â”œâ”€â”€ WebSocket Broadcast: <5ms to connected clients
â”œâ”€â”€ Client Updates: Real-time dashboard updates
â””â”€â”€ Acknowledgment: Guaranteed message processing

End-to-End Latency:
â”œâ”€â”€ Simulation â†’ Redis: <10ms
â”œâ”€â”€ Redis â†’ API Gateway: <5ms
â”œâ”€â”€ API Gateway â†’ WebSocket: <5ms
â”œâ”€â”€ WebSocket â†’ Client: <10ms
â””â”€â”€ Total: <30ms for real-time updates
```

## ğŸ”„ **Connection Pool Management (gRPC)**

### **Connection Pool Architecture**
```go
type ServiceMeshClient struct {
    serviceName    string
    connections    map[string]*ConnectionPool
    discovery      ServiceDiscovery
    healthChecker  HealthChecker
}

type ConnectionPool struct {
    targetService  string
    targetAddress  string
    minConnections int    // 5 (always warm)
    maxConnections int    // 20 (scale up under load)
    currentConns   []*grpc.ClientConn
    loadBalancer   LoadBalancer
    circuitBreaker CircuitBreaker
    metrics        PoolMetrics
}
```

### **Multiple Instance Communication**

#### **Service Instance Discovery**
```
Example Scenario: 3 API Gateway + 2 Auth Service + 1 Project + 1 Simulation

Service Registry (Redis):
â”œâ”€â”€ services:api-gateway:instance-1 â†’ {"grpc_port": 8000, "http_port": 8001, "status": "healthy"}
â”œâ”€â”€ services:api-gateway:instance-2 â†’ {"grpc_port": 8000, "http_port": 8001, "status": "healthy"}
â”œâ”€â”€ services:api-gateway:instance-3 â†’ {"grpc_port": 8000, "http_port": 8001, "status": "healthy"}
â”œâ”€â”€ services:auth-service:instance-1 â†’ {"grpc_port": 9000, "http_port": 9001, "status": "healthy"}
â”œâ”€â”€ services:auth-service:instance-2 â†’ {"grpc_port": 9000, "http_port": 9001, "status": "healthy"}
â”œâ”€â”€ services:project-service:instance-1 â†’ {"grpc_port": 10000, "http_port": 10001, "status": "healthy"}
â””â”€â”€ services:simulation-service:instance-1 â†’ {"grpc_port": 11000, "http_port": 11001, "status": "healthy"}
```

#### **Connection Distribution Strategy**
```
Each service instance connects to ALL instances of ALL other services:

Auth Service Instance 1 gRPC Connections:
â”œâ”€â”€ api-gateway:instance-1 (20 connections)
â”œâ”€â”€ api-gateway:instance-2 (20 connections)
â”œâ”€â”€ api-gateway:instance-3 (20 connections)
â”œâ”€â”€ project-service:instance-1 (20 connections)
â”œâ”€â”€ simulation-service:instance-1 (20 connections)
â””â”€â”€ Total: 100 gRPC connections

API Gateway Instance 1 gRPC Connections:
â”œâ”€â”€ auth-service:instance-1 (20 connections)
â”œâ”€â”€ auth-service:instance-2 (20 connections)
â”œâ”€â”€ project-service:instance-1 (20 connections)
â”œâ”€â”€ simulation-service:instance-1 (20 connections)
â””â”€â”€ Total: 80 gRPC connections

System Total: ~540 gRPC connections (7 instances Ã— average 77 connections each)
```

#### **Load Balancing Across Instances**
```go
type MultiInstanceClient struct {
    serviceName     string
    instances       map[string]*ConnectionPool  // instance-id -> connection pool
    loadBalancer    *RoundRobinLB
    discovery       ServiceDiscovery
    healthChecker   HealthChecker
}

// Make gRPC call with automatic load balancing
func (mic *MultiInstanceClient) Call(ctx context.Context, method string, req interface{}) (interface{}, error) {
    // Get healthy instances
    healthyInstances := mic.getHealthyInstances()
    if len(healthyInstances) == 0 {
        return nil, errors.New("no healthy instances available")
    }

    // Round-robin selection
    selectedInstance := mic.loadBalancer.Next(healthyInstances)

    // Get connection from selected instance pool
    conn, err := selectedInstance.GetConnection()
    if err != nil {
        // Try next instance on failure
        return mic.retryWithNextInstance(ctx, method, req, selectedInstance)
    }

    // Make gRPC call
    return mic.makeGRPCCall(ctx, conn, method, req)
}
```

### **Dynamic Connection Scaling Logic**

#### **Traffic-Based Auto-Scaling Algorithm**
```go
func (pool *DynamicConnectionPool) autoScale() {
    metrics := pool.getMetrics()

    // Scale Up Decision
    if pool.shouldScaleUp(metrics) && pool.canScaleUp() {
        if pool.globalScaler.requestConnectionIncrease(pool) {
            pool.addConnection()
            pool.metrics.LastScaleAction = time.Now()
            log.Printf("Scaled up: %s now has %d connections",
                       pool.instanceID, len(pool.currentConns))
        }
    }

    // Scale Down Decision (with delay to prevent thrashing)
    if pool.shouldScaleDown(metrics) && pool.canScaleDown() {
        pool.removeConnection()
        pool.globalScaler.releaseConnection()
        pool.metrics.LastScaleAction = time.Now()
        log.Printf("Scaled down: %s now has %d connections",
                   pool.instanceID, len(pool.currentConns))
    }
}

func (pool *DynamicConnectionPool) shouldScaleUp(metrics *PoolMetrics) bool {
    return (metrics.ConnectionUtilization > 0.8 ||     // >80% utilization
            metrics.QueueDepth > 10 ||                 // Queue backing up
            metrics.RequestsPerSecond > 100 ||         // High traffic
            metrics.AverageLatency > 50*time.Millisecond) && // High latency
           metrics.ErrorRate < 0.05                    // Service is healthy
}

func (pool *DynamicConnectionPool) shouldScaleDown(metrics *PoolMetrics) bool {
    timeSinceLastScale := time.Since(metrics.LastScaleAction)
    return metrics.ConnectionUtilization < 0.3 &&      // <30% utilization
           metrics.QueueDepth < 2 &&                   // Low queue depth
           timeSinceLastScale > 5*time.Minute &&       // 5 min delay
           len(pool.currentConns) > pool.minConnections // Above minimum
}
```

#### **Global Connection Management**
```go
type GlobalConnectionScaler struct {
    maxTotalConnections int                    // 1000 per service instance
    currentTotal        int                    // Current total across all pools
    priorityServices    []string               // ["auth-service", "project-service", ...]
    servicePools        map[string][]*DynamicConnectionPool
    rebalanceThreshold  float64                // 0.9 (90% of max)
    mutex              sync.RWMutex
}

func (gcs *GlobalConnectionScaler) requestConnectionIncrease(requestingPool *DynamicConnectionPool) bool {
    gcs.mutex.Lock()
    defer gcs.mutex.Unlock()

    // Simple case: under global limit
    if gcs.currentTotal < gcs.maxTotalConnections {
        gcs.currentTotal++
        return true
    }

    // Complex case: need to rebalance
    return gcs.rebalanceConnections(requestingPool)
}

func (gcs *GlobalConnectionScaler) rebalanceConnections(requestingPool *DynamicConnectionPool) bool {
    requestingService := requestingPool.serviceName
    requestingPriority := gcs.getServicePriority(requestingService)

    // Find lower priority services with excess connections
    for priority := len(gcs.priorityServices) - 1; priority > requestingPriority; priority-- {
        serviceName := gcs.priorityServices[priority]

        if pool := gcs.findPoolWithExcessConnections(serviceName); pool != nil {
            pool.forceScaleDown()
            gcs.currentTotal-- // Released one connection
            gcs.currentTotal++ // Allocated to requesting pool

            log.Printf("Rebalanced: Moved connection from %s to %s",
                       serviceName, requestingService)
            return true
        }
    }

    log.Printf("Connection request denied: No available connections for %s",
               requestingService)
    return false
}

// Service priority order (0 = highest priority)
func (gcs *GlobalConnectionScaler) getServicePriority(serviceName string) int {
    for i, service := range gcs.priorityServices {
        if service == serviceName {
            return i
        }
    }
    return len(gcs.priorityServices) // Lowest priority for unknown services
}
```

#### **Connection Efficiency Metrics**
```
Real-World Scaling Example:

Normal Traffic (9 AM - 5 PM):
â”œâ”€â”€ Auth Service: 8-12 connections per target (medium priority calls)
â”œâ”€â”€ Project Service: 5-8 connections per target (steady CRUD operations)
â”œâ”€â”€ Simulation Service: 5-6 connections per target (low simulation activity)
â”œâ”€â”€ API Gateway: 6-10 connections per target (steady client requests)
â””â”€â”€ Total System: ~200-300 connections (vs 540 static)

Peak Traffic (Product Launch):
â”œâ”€â”€ Auth Service: 18-20 connections per target (high authentication load)
â”œâ”€â”€ Project Service: 15-18 connections per target (many new projects)
â”œâ”€â”€ Simulation Service: 12-15 connections per target (demo simulations)
â”œâ”€â”€ API Gateway: 16-20 connections per target (high client load)
â””â”€â”€ Total System: ~400-500 connections (scales automatically)

Low Traffic (Nights/Weekends):
â”œâ”€â”€ Auth Service: 5 connections per target (minimum warm connections)
â”œâ”€â”€ Project Service: 5 connections per target (minimum warm connections)
â”œâ”€â”€ Simulation Service: 5 connections per target (minimum warm connections)
â”œâ”€â”€ API Gateway: 5 connections per target (minimum warm connections)
â””â”€â”€ Total System: ~105 connections (80% reduction from static)

Scaling Performance:
â”œâ”€â”€ Scale Up Time: <500ms (add new connection)
â”œâ”€â”€ Scale Down Time: 5 minutes (prevent thrashing)
â”œâ”€â”€ Rebalancing Time: <1 second (move connection between services)
â”œâ”€â”€ Health Detection: <30 seconds (remove unhealthy connections)
â””â”€â”€ Memory Efficiency: 60-80% improvement over static pools
```

## ğŸ¯ **Service Communication Patterns**

### **Two-Type Communication Examples**

#### **Authentication Flow (gRPC + Redis)**
```
Synchronous (gRPC):
1. API Gateway receives client request with JWT token
2. API Gateway â†’ Auth Service (gRPC): ValidateToken(token, "api-gateway")
3. Auth Service validates token and returns user context immediately
4. API Gateway â†’ Target Service (gRPC): Request with user context
5. Target Service processes request with validated user info

Asynchronous (Redis):
6. Auth Service â†’ Redis: Publish("auth:events:login", {user_id, timestamp})
7. API Gateway subscribes to "auth:events:*" and broadcasts to WebSocket clients
8. Other services can subscribe to auth events for analytics, logging, etc.
```

#### **Project Creation Flow (gRPC + Redis)**
```
Synchronous (gRPC):
1. API Gateway â†’ Auth Service (gRPC): ValidateToken(token)
2. API Gateway â†’ Project Service (gRPC): CreateProject(user_id, project_data)
3. Project Service â†’ Auth Service (gRPC): CheckPermission(user_id, "project:create")
4. Project Service creates project and returns project_id immediately

Asynchronous (Redis):
5. Project Service â†’ Redis: Publish("project:events:created", {project_id, user_id})
6. API Gateway receives event and broadcasts to WebSocket clients
7. Analytics Service processes project creation for metrics
8. Notification Service sends welcome email via "async:email:queue"
```

#### **Real-time Simulation Flow (gRPC + Redis)**
```
Synchronous (gRPC):
1. API Gateway â†’ Project Service (gRPC): GetProject(project_id)
2. API Gateway â†’ Simulation Service (gRPC): StartSimulation(project_id, config)
3. Simulation Service â†’ Auth Service (gRPC): CheckPermission(user_id, "simulation:start")
4. Simulation Service returns simulation_id immediately

Asynchronous (Redis):
5. Simulation Service â†’ Redis: Publish("simulation:events:started", {simulation_id})
6. Simulation Service â†’ Redis: Publish("simulation:data:{id}", metrics) [100+ times/second]
7. API Gateway subscribes to "simulation:data:*" and streams to WebSocket clients
8. Heavy analytics processing via "async:analytics:queue"
```

#### **Multiple Instance Load Balancing**
```
Example: 3 API Gateway instances calling 2 Auth Service instances

API Gateway Instance 1:
â”œâ”€â”€ Receives client request
â”œâ”€â”€ Round-robin selects Auth Service Instance 2
â”œâ”€â”€ Makes gRPC call: ValidateToken()
â”œâ”€â”€ Gets immediate response
â””â”€â”€ Continues processing

If Auth Service Instance 2 fails:
â”œâ”€â”€ Circuit breaker detects failure
â”œâ”€â”€ Automatically routes to Auth Service Instance 1
â”œâ”€â”€ Client request continues without interruption
â””â”€â”€ Failed instance is marked unhealthy in service registry
```

## ğŸ“Š **Performance Specifications**

### **gRPC Performance with Dynamic Scaling (Synchronous)**
```
Performance Targets:
â”œâ”€â”€ API Gateway Calls: <10ms (client-facing operations)
â”œâ”€â”€ Auth Service Calls: <5ms (most critical - token validation)
â”œâ”€â”€ Project Service Calls: <10ms (CRUD operations)
â”œâ”€â”€ Simulation Service Calls: <15ms (complex operations)
â”œâ”€â”€ Connection Pool Utilization: 60-80% optimal (dynamic scaling maintains this)
â”œâ”€â”€ Circuit Breaker Threshold: 50% error rate over 10 seconds
â”œâ”€â”€ Health Check Interval: 30 seconds
â””â”€â”€ Connection Scaling: <500ms to add connections, 5min delay to remove

Dynamic Scaling Performance:
â”œâ”€â”€ Scale Up Trigger Latency: <100ms (detect high utilization)
â”œâ”€â”€ New Connection Establishment: <500ms
â”œâ”€â”€ Load Rebalancing: <1 second across instances
â”œâ”€â”€ Global Connection Rebalancing: <1 second between services
â”œâ”€â”€ Scale Down Evaluation: Every 30 seconds
â”œâ”€â”€ Scale Down Execution: After 5 minute delay
â””â”€â”€ Connection Pool Efficiency: 60-80% utilization maintained
```

### **Redis Pub/Sub Performance (Asynchronous)**
```
Performance Targets:
â”œâ”€â”€ Message Publishing: <1ms latency
â”œâ”€â”€ Message Delivery: <1ms to subscribers
â”œâ”€â”€ High-Frequency Channels: 100,000+ messages/second (simulation data)
â”œâ”€â”€ Event Channels: 1,000+ messages/second (auth, project events)
â”œâ”€â”€ Background Queues: 10,000+ messages/second (async processing)
â”œâ”€â”€ Channel Subscription: <10ms to establish
â””â”€â”€ Memory Usage: <1KB per channel, <1KB per subscriber
```

### **Multiple Instance Performance**
```
Scaling Performance:
â”œâ”€â”€ Service Discovery: <100ms to detect new instances
â”œâ”€â”€ Connection Establishment: <500ms to new instances
â”œâ”€â”€ Load Balancing: <1ms overhead per request
â”œâ”€â”€ Failover Time: <2 seconds to detect and route around failures
â”œâ”€â”€ Instance Health Checks: Every 30 seconds
â””â”€â”€ Connection Pool Rebalancing: <5 seconds after instance changes
```

### **Monitoring Metrics with Dynamic Scaling**
```
gRPC Dynamic Pool Metrics:
â”œâ”€â”€ Active Connections: Current connection count per instance (5-20 range)
â”œâ”€â”€ Connection Utilization: Percentage of connections actively serving requests
â”œâ”€â”€ Request Queue Depth: Pending requests per connection pool
â”œâ”€â”€ Response Latency: P50, P95, P99 response times per service
â”œâ”€â”€ Error Rate: Failed requests percentage per service
â”œâ”€â”€ Circuit Breaker Status: Open/closed state per service instance
â”œâ”€â”€ Connection Health: Healthy/unhealthy connection count
â”œâ”€â”€ Scaling Events: Scale up/down events per time period
â”œâ”€â”€ Scaling Latency: Time to add/remove connections
â”œâ”€â”€ Global Connection Usage: Total connections vs limit (1000)
â”œâ”€â”€ Priority Rebalancing: Connection moves between services
â””â”€â”€ Pool Efficiency: Utilization improvement over static pools

Connection Scaling Metrics:
â”œâ”€â”€ Scale Up Triggers: Count of scale up events by trigger type
â”‚   â”œâ”€â”€ High Utilization (>80%): Count per service
â”‚   â”œâ”€â”€ Queue Depth (>10): Count per service
â”‚   â”œâ”€â”€ High RPS (>100): Count per service
â”‚   â””â”€â”€ High Latency (>50ms): Count per service
â”œâ”€â”€ Scale Down Events: Count of scale down events (after 5min delay)
â”œâ”€â”€ Rebalancing Events: Connections moved between services
â”œâ”€â”€ Connection Efficiency: Utilization before/after scaling
â”œâ”€â”€ Memory Savings: Memory usage vs static pools
â””â”€â”€ Resource Contention: Times connection requests were denied

Redis Pub/Sub Metrics:
â”œâ”€â”€ Message Throughput: Messages/second per channel
â”œâ”€â”€ Subscriber Count: Active subscribers per channel
â”œâ”€â”€ Message Latency: Publish-to-delivery time
â”œâ”€â”€ Channel Memory Usage: Memory per channel
â”œâ”€â”€ Connection Count: Active Redis connections
â””â”€â”€ Failed Deliveries: Messages that failed to deliver

Service Discovery Metrics:
â”œâ”€â”€ Instance Count: Active instances per service
â”œâ”€â”€ Discovery Latency: Time to detect instance changes
â”œâ”€â”€ Health Check Success Rate: Percentage of successful health checks
â”œâ”€â”€ Dynamic Pool Size: Current connections per service instance
â”œâ”€â”€ Load Balancing Distribution: Request distribution across instances
â”œâ”€â”€ Connection Pool Rebalancing: Time to adjust to instance changes
â””â”€â”€ Global Resource Utilization: System-wide connection usage
```

---

*Last Updated: January 2025*  
*Version: 1.0 - Internal Mesh Communication*  
*Status: Protocol Definitions Complete*
